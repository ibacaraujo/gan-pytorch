{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZ/DsUpjel2olb4ngCqlou",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibacaraujo/gan-pytorch/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uQjZza7Nb4n",
        "colab_type": "text"
      },
      "source": [
        "# Generative Adversarial Networks in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBhu5kVSNghE",
        "colab_type": "text"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzHV3aqXNLuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P52YyRF2P07A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matplotlib_is_available = True\n",
        "try:\n",
        "  from matplotlib import pyplot as plt\n",
        "except ImportError:\n",
        "  print(\"Will skip plotting; matplotlib is not available.\")\n",
        "  matplotlib_is_available = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0le2FsugNi6l",
        "colab_type": "text"
      },
      "source": [
        "## Dataset.\n",
        "**Parameters and functions related to the data usage.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xZs_aXANa3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data params\n",
        "data_mean = 4\n",
        "data_stddev = 1.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0tSCD3BN2C6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e405c300-035b-496a-cf3e-8e96056c6ad6"
      },
      "source": [
        "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
        "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
        "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
        "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
        "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
        "\n",
        "print(\"Using data [%s]\" % (name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using data [Only 4 moments]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTo7tVO8OUuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_distribution_sampler(mu, sigma):\n",
        "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaHCoL00O4s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator_input_sampler():\n",
        "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip6xf1mvQVDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract(v):\n",
        "    return v.data.storage().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi2A3HrtQXaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stats(d):\n",
        "    return [np.mean(d), np.std(d)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TYWjHAiQYca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_moments(d):\n",
        "    # Return the first 4 moments of the data provided\n",
        "    mean = torch.mean(d)\n",
        "    diffs = d - mean\n",
        "    var = torch.mean(torch.pow(diffs, 2.0))\n",
        "    std = torch.pow(var, 0.5)\n",
        "    zscores = diffs / std\n",
        "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
        "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
        "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
        "    return final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fptsKT1wQZpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
        "    mean = torch.mean(data.data, 1, keepdim=True)\n",
        "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
        "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
        "    if remove_raw_data:\n",
        "        return torch.cat([diffs], 1)\n",
        "    else:\n",
        "        return torch.cat([data, diffs], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug3wVKCyQEoA",
        "colab_type": "text"
      },
      "source": [
        "## Models.\n",
        "**Generator and discriminator definitions.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHXVz4dpQHv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, f):\n",
        "        super(Generator, self).__init__()\n",
        "        self.map1 = nn.Linear(input_size, hidden_size)\n",
        "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.map3 = nn.Linear(hidden_size, output_size)\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.map1(x)\n",
        "        x = self.f(x)\n",
        "        x = self.map2(x)\n",
        "        x = self.f(x)\n",
        "        x = self.map3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxpwusvxQOYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, f):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.map1 = nn.Linear(input_size, hidden_size)\n",
        "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.map3 = nn.Linear(hidden_size, output_size)\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.f(self.map1(x))\n",
        "        x = self.f(self.map2(x))\n",
        "        return self.f(self.map3(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBb4qEWwQe4y",
        "colab_type": "text"
      },
      "source": [
        "## Training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4J-qlaIQrSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    # Model parameters\n",
        "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
        "    g_hidden_size = 5     # Generator complexity\n",
        "    g_output_size = 1     # Size of generated output vector\n",
        "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
        "    d_hidden_size = 10    # Discriminator complexity\n",
        "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
        "    minibatch_size = d_input_size\n",
        "\n",
        "    d_learning_rate = 1e-3\n",
        "    g_learning_rate = 1e-3\n",
        "    sgd_momentum = 0.9\n",
        "\n",
        "    num_epochs = 200\n",
        "    print_interval = 100\n",
        "    d_steps = 20\n",
        "    g_steps = 20\n",
        "\n",
        "    dfe, dre, ge = 0, 0, 0\n",
        "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
        "\n",
        "    discriminator_activation_function = torch.sigmoid\n",
        "    generator_activation_function = torch.tanh\n",
        "\n",
        "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
        "    gi_sampler = get_generator_input_sampler()\n",
        "    G = Generator(input_size=g_input_size,\n",
        "                  hidden_size=g_hidden_size,\n",
        "                  output_size=g_output_size,\n",
        "                  f=generator_activation_function)\n",
        "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
        "                      hidden_size=d_hidden_size,\n",
        "                      output_size=d_output_size,\n",
        "                      f=discriminator_activation_function)\n",
        "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
        "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for d_index in range(d_steps):\n",
        "            # 1. Train D on real+fake\n",
        "            D.zero_grad()\n",
        "\n",
        "            #  1A: Train D on real\n",
        "            d_real_data = Variable(d_sampler(d_input_size))\n",
        "            d_real_decision = D(preprocess(d_real_data))\n",
        "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true\n",
        "            d_real_error.backward() # compute/store gradients, but don't change params\n",
        "\n",
        "            #  1B: Train D on fake\n",
        "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
        "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
        "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
        "            d_fake_error.backward()\n",
        "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
        "\n",
        "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
        "\n",
        "        for g_index in range(g_steps):\n",
        "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "            G.zero_grad()\n",
        "\n",
        "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
        "            g_fake_data = G(gen_input)\n",
        "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
        "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
        "\n",
        "            g_error.backward()\n",
        "            g_optimizer.step()  # Only optimizes G's parameters\n",
        "            ge = extract(g_error)[0]\n",
        "\n",
        "        if epoch % print_interval == 0:\n",
        "            print(\"Epoch %s: D error (%s real, %s fake) G error (%s); Real (%s),  Fake (%s) \" %\n",
        "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
        "\n",
        "    if matplotlib_is_available:\n",
        "        print(\"Plotting the generated distribution...\")\n",
        "        values = extract(g_fake_data)\n",
        "        plt.hist(values, bins=50)\n",
        "        plt.xlabel('Value')\n",
        "        plt.ylabel('Count')\n",
        "        plt.title('Histogram of Generated Distribution')\n",
        "        plt.grid(True)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SP7XX9SQwny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "f787c2a5-d14e-4209-fc9b-0f96950238d4"
      },
      "source": [
        "train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: D error (0.9916362166404724 real, 0.46392273902893066 fake) G error (0.9865283370018005); Real ([3.9654017032980917, 1.2064845632149501]),  Fake ([-0.32895818281173705, 0.029689121682687634]) \n",
            "Epoch 100: D error (0.5322058200836182 real, 0.47185030579566956 fake) G error (0.9614695906639099); Real ([4.0085267609357835, 1.2226148707393736]),  Fake ([3.4715738019943236, 0.10092464793893689]) \n",
            "Plotting the generated distribution...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMDOznEPBzMxyDgUzM8s5FMzMLPf/AUEYxbnKQBDWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}